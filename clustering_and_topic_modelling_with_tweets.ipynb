{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data: https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter\n",
    "#### using this file everydayhealth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3239\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304596701757464576</td>\n",
       "      <td>Thu Feb 21 14:21:27 +0000 2013</td>\n",
       "      <td>#FastFood Makes Up 11 Percent of #Calories in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304595191329853441</td>\n",
       "      <td>Thu Feb 21 14:15:27 +0000 2013</td>\n",
       "      <td>10 snacks to help you lose weight, burn fat, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304587659018371072</td>\n",
       "      <td>Thu Feb 21 13:45:31 +0000 2013</td>\n",
       "      <td>10 foods that boost your skin AND slim your wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304580073380524032</td>\n",
       "      <td>Thu Feb 21 13:15:22 +0000 2013</td>\n",
       "      <td>What a heart attack feels like in women (it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304572560270573569</td>\n",
       "      <td>Thu Feb 21 12:45:31 +0000 2013</td>\n",
       "      <td>#McDonalds oatmeal has almost 7 teaspoons of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tw_id                            date  \\\n",
       "0  304596701757464576  Thu Feb 21 14:21:27 +0000 2013   \n",
       "1  304595191329853441  Thu Feb 21 14:15:27 +0000 2013   \n",
       "2  304587659018371072  Thu Feb 21 13:45:31 +0000 2013   \n",
       "3  304580073380524032  Thu Feb 21 13:15:22 +0000 2013   \n",
       "4  304572560270573569  Thu Feb 21 12:45:31 +0000 2013   \n",
       "\n",
       "                                               tweet  \n",
       "0  #FastFood Makes Up 11 Percent of #Calories in ...  \n",
       "1  10 snacks to help you lose weight, burn fat, a...  \n",
       "2  10 foods that boost your skin AND slim your wa...  \n",
       "3  What a heart attack feels like in women (it's ...  \n",
       "4  #McDonalds oatmeal has almost 7 teaspoons of s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Health-Tweets'\n",
    "col_names = ['tw_id', 'date', 'tweet']\n",
    "df = pd.read_csv(os.path.join(path, 'everydayhealth.txt'), sep=\"|\", names=col_names)\n",
    "print len(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'fastfood make percent calorie diet',\n",
       " u'snack help lose weight burn build muscle',\n",
       " u'food boost skin slim waistline',\n",
       " u'heart attack feel like woman different gored',\n",
       " u'mcdonalds oatmeal teaspoon sugar healthy fast food isnt',\n",
       " u'food boost skin slim waistline',\n",
       " u'skipping kegels using talcum powder vaginal health mistake youre probably making',\n",
       " u'food boost skin slim waistline',\n",
       " u'today happier perform random kindness itll make feel better',\n",
       " u'depression isnt everybody different face disorder']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some preprocessing\n",
    "\n",
    "def pre_processing(data_frame, txt_clm):\n",
    "    \n",
    "    df_txt = data_frame.copy()\n",
    "    \n",
    "    # lower case \n",
    "    df_txt['lower_txt'] = df_txt[txt_clm].str.lower()\n",
    "    \n",
    "    #replace RTs with ''\n",
    "    df_txt['links_rm'] = df_txt['lower_txt'].apply(lambda v: v.replace('rt', ''))\n",
    "    \n",
    "    # remove punctuation\n",
    "    df_txt['punc_rm'] = df_txt['lower_txt'].str.replace('[^\\w\\s]','')\n",
    "    \n",
    "    # replace hyperlinks with ''\n",
    "    df_txt['links_rm'] = df_txt['punc_rm'].apply(lambda v: re.sub(r'http\\S+', '', v))\n",
    "    \n",
    "    # remove stopwords\n",
    "    df_txt['stopwords_rm'] = df_txt['links_rm'].apply(lambda x: \" \".join(x for x in x.split() if x not in ENGLISH_STOP_WORDS))\n",
    "    \n",
    "     # lemmatize all the words\n",
    "    df_txt['lemmatize_text'] = df_txt['stopwords_rm'].apply(lambda v: \" \".join([word_lm.lemmatize(i) for i in v.split()]))\n",
    "    \n",
    "    df_txt['processed_text'] = df_txt['lemmatize_text'].apply(lambda x: word_tokenize(x))\n",
    "    \n",
    "    df_txt['raw_text'] = df_txt['processed_text'].apply(lambda x: \" \".join(w for w in x if len(w)> 3))\n",
    "    \n",
    "    return df_txt[['tweet', 'raw_text']]\n",
    "\n",
    "tweets_data = df.copy()\n",
    "processed_df = pre_processing(tweets_data[['tweet']], 'tweet')\n",
    "processed_df['raw_text'].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>everyday health daily digest</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>food boost skin slim waistline</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>food longer life</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>eating habit pack pound</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>soda drinker listen reason kick soda habit</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>meat surprising food thatll spike blood sugar</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>fiberrich food diet asap</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>calorie today</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adhd characteristic actually huge plus choosin...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>health symptom shouldnt ignore menshealth</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_text  count\n",
       "725                        everyday health daily digest     42\n",
       "817                      food boost skin slim waistline     24\n",
       "824                                    food longer life     22\n",
       "542                             eating habit pack pound     14\n",
       "1853         soda drinker listen reason kick soda habit     12\n",
       "1353      meat surprising food thatll spike blood sugar     11\n",
       "785                            fiberrich food diet asap     11\n",
       "247                                       calorie today     10\n",
       "14    adhd characteristic actually huge plus choosin...     10\n",
       "968           health symptom shouldnt ignore menshealth      9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a groupby of raw text, since preprocessing now we are able to group them\n",
    "group_text = processed_df.groupby(['raw_text'], as_index=False).count()\n",
    "group_text = group_text.rename(columns={'tweet': 'count'})\n",
    "group_text.sort_values('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>1089</th>\n",
       "      <th>11am</th>\n",
       "      <th>11ampst</th>\n",
       "      <th>1200</th>\n",
       "      <th>12noon</th>\n",
       "      <th>13for13</th>\n",
       "      <th>13in2013</th>\n",
       "      <th>1520lbs</th>\n",
       "      <th>1pmet</th>\n",
       "      <th>...</th>\n",
       "      <th>youself</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerocalorie</th>\n",
       "      <th>zocor</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000  1089  11am  11ampst  1200  12noon  13for13  13in2013  1520lbs  1pmet  \\\n",
       "0   0.0   0.0   0.0      0.0   0.0     0.0      0.0       0.0      0.0    0.0   \n",
       "1   0.0   0.0   0.0      0.0   0.0     0.0      0.0       0.0      0.0    0.0   \n",
       "2   0.0   0.0   0.0      0.0   0.0     0.0      0.0       0.0      0.0    0.0   \n",
       "\n",
       "   ...   youself  youth  youtube  youve  yummy  zero  zerocalorie  zocor  \\\n",
       "0  ...       0.0    0.0      0.0    0.0    0.0   0.0          0.0    0.0   \n",
       "1  ...       0.0    0.0      0.0    0.0    0.0   0.0          0.0    0.0   \n",
       "2  ...       0.0    0.0      0.0    0.0    0.0   0.0          0.0    0.0   \n",
       "\n",
       "   zucchini  zzzs  \n",
       "0       0.0   0.0  \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "\n",
       "[3 rows x 3543 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(processed_df['raw_text'])\n",
    "feature_names = vectorizer.get_feature_names() # num phrases \n",
    "feature_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'worry' u'sooner' u'highincome' u'sicker' u'country' u'american' u'zzzs'\n",
      " u'fightdepression' u'finger' u'finding' u'financial' u'finally'\n",
      " u'filtered' u'filling' u'figure' u'fighting' u'fiery' u'fight'\n",
      " u'fitandfabliving' u'field' u'fibromyalgia' u'fibrillation' u'fiberrich'\n",
      " u'fiber' u'fewer' u'fever' u'feng' u'fend' u'fence' u'fish']\n"
     ]
    }
   ],
   "source": [
    "# get top n features\n",
    "feature_array = np.array(feature_names)\n",
    "tfidf_sorting = np.argsort(X.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 30\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 1656\n",
      "Cluster 1: 307\n",
      "Cluster 2: 116\n",
      "Cluster 3: 144\n",
      "Cluster 4: 106\n",
      "Cluster 5: 49\n",
      "Cluster 6: 861\n"
     ]
    }
   ],
   "source": [
    "# apply k means cluster, choosing k as 7\n",
    "true_k = 7\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "clusters = model.labels_.tolist()\n",
    "cluster_items = Counter(clusters)\n",
    "for k in cluster_items:\n",
    "    print \"Cluster {}: {}\".format(k, cluster_items[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0</th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "      <th>Cluster 3</th>\n",
       "      <th>Cluster 4</th>\n",
       "      <th>Cluster 5</th>\n",
       "      <th>Cluster 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exercise</td>\n",
       "      <td>food</td>\n",
       "      <td>reason</td>\n",
       "      <td>best</td>\n",
       "      <td>really</td>\n",
       "      <td>pound</td>\n",
       "      <td>healthtalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health</td>\n",
       "      <td>weight</td>\n",
       "      <td>soda</td>\n",
       "      <td>worst</td>\n",
       "      <td>sleep</td>\n",
       "      <td>pack</td>\n",
       "      <td>everydayhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jillianmichaels</td>\n",
       "      <td>lose</td>\n",
       "      <td>fish</td>\n",
       "      <td>food</td>\n",
       "      <td>work</td>\n",
       "      <td>habit</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calorie</td>\n",
       "      <td>life</td>\n",
       "      <td>lifeenhancing</td>\n",
       "      <td>waistline</td>\n",
       "      <td>share</td>\n",
       "      <td>eating</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better</td>\n",
       "      <td>longer</td>\n",
       "      <td>losing</td>\n",
       "      <td>skin</td>\n",
       "      <td>healthyliving</td>\n",
       "      <td>lose</td>\n",
       "      <td>eatsmartbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>healthy</td>\n",
       "      <td>loss</td>\n",
       "      <td>drinker</td>\n",
       "      <td>slim</td>\n",
       "      <td>weight</td>\n",
       "      <td>huge</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>help</td>\n",
       "      <td>diet</td>\n",
       "      <td>kick</td>\n",
       "      <td>boost</td>\n",
       "      <td>need</td>\n",
       "      <td>characteristic</td>\n",
       "      <td>everyday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>secret</td>\n",
       "      <td>sugar</td>\n",
       "      <td>listen</td>\n",
       "      <td>protein</td>\n",
       "      <td>remedy</td>\n",
       "      <td>adhdfriendly</td>\n",
       "      <td>digest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diet</td>\n",
       "      <td>spike</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>snack</td>\n",
       "      <td>home</td>\n",
       "      <td>career</td>\n",
       "      <td>daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>risk</td>\n",
       "      <td>blood</td>\n",
       "      <td>youre</td>\n",
       "      <td>treat</td>\n",
       "      <td>lossspiration</td>\n",
       "      <td>choosing</td>\n",
       "      <td>psoriasis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cluster 0 Cluster 1      Cluster 2  Cluster 3      Cluster 4  \\\n",
       "0         exercise      food         reason       best         really   \n",
       "1           health    weight           soda      worst          sleep   \n",
       "2  jillianmichaels      lose           fish       food           work   \n",
       "3          calorie      life  lifeenhancing  waistline          share   \n",
       "4           better    longer         losing       skin  healthyliving   \n",
       "5          healthy      loss        drinker       slim         weight   \n",
       "6             help      diet           kick      boost           need   \n",
       "7           secret     sugar         listen    protein         remedy   \n",
       "8             diet     spike      chocolate      snack           home   \n",
       "9             risk     blood          youre      treat  lossspiration   \n",
       "\n",
       "        Cluster 5       Cluster 6  \n",
       "0           pound      healthtalk  \n",
       "1            pack  everydayhealth  \n",
       "2           habit           today  \n",
       "3          eating          health  \n",
       "4            lose      eatsmartbd  \n",
       "5            huge            join  \n",
       "6  characteristic        everyday  \n",
       "7    adhdfriendly          digest  \n",
       "8          career           daily  \n",
       "9        choosing       psoriasis  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort cluster centers by proximity to centroid\n",
    "cl_cols = ['Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Cluster 6']\n",
    "cluster_df = pd.DataFrame(columns = cl_cols)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(true_k):\n",
    "    join_words = []\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        join_words.append(feature_names[ind])\n",
    "    cluster_df[\"Cluster {}\".format(i)] = join_words\n",
    "    \n",
    "cluster_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digest</td>\n",
       "      <td>food</td>\n",
       "      <td>healthtalk</td>\n",
       "      <td>weight</td>\n",
       "      <td>calorie</td>\n",
       "      <td>boost</td>\n",
       "      <td>eating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everyday</td>\n",
       "      <td>life</td>\n",
       "      <td>join</td>\n",
       "      <td>lose</td>\n",
       "      <td>today</td>\n",
       "      <td>waistline</td>\n",
       "      <td>habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily</td>\n",
       "      <td>longer</td>\n",
       "      <td>everydayhealth</td>\n",
       "      <td>loss</td>\n",
       "      <td>burn</td>\n",
       "      <td>slim</td>\n",
       "      <td>pound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>change</td>\n",
       "      <td>follow</td>\n",
       "      <td>help</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>skin</td>\n",
       "      <td>pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>eatsmartbd</td>\n",
       "      <td>whats</td>\n",
       "      <td>easy</td>\n",
       "      <td>food</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>snack</td>\n",
       "      <td>sugar</td>\n",
       "      <td>heart</td>\n",
       "      <td>healthy</td>\n",
       "      <td>sneaky</td>\n",
       "      <td>best</td>\n",
       "      <td>soda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ignore</td>\n",
       "      <td>spike</td>\n",
       "      <td>chat</td>\n",
       "      <td>trying</td>\n",
       "      <td>just</td>\n",
       "      <td>blood</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shouldnt</td>\n",
       "      <td>blood</td>\n",
       "      <td>vegan</td>\n",
       "      <td>reason</td>\n",
       "      <td>reason</td>\n",
       "      <td>sugar</td>\n",
       "      <td>complexion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>asap</td>\n",
       "      <td>question</td>\n",
       "      <td>dieting</td>\n",
       "      <td>skip</td>\n",
       "      <td>plus</td>\n",
       "      <td>drinker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>symptom</td>\n",
       "      <td>fiberrich</td>\n",
       "      <td>today</td>\n",
       "      <td>losing</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>metabolism</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic 0    Topic 1         Topic 2  Topic 3    Topic 4     Topic 5  \\\n",
       "0    digest       food      healthtalk   weight    calorie       boost   \n",
       "1  everyday       life            join     lose      today   waistline   \n",
       "2     daily     longer  everydayhealth     loss       burn        slim   \n",
       "3    health     change          follow     help  chocolate        skin   \n",
       "4     worst      worst      eatsmartbd    whats       easy        food   \n",
       "5     snack      sugar           heart  healthy     sneaky        best   \n",
       "6    ignore      spike            chat   trying       just       blood   \n",
       "7  shouldnt      blood           vegan   reason     reason       sugar   \n",
       "8      2013       asap        question  dieting       skip        plus   \n",
       "9   symptom  fiberrich           today   losing   tomorrow  metabolism   \n",
       "\n",
       "      Topic 6  \n",
       "0      eating  \n",
       "1       habit  \n",
       "2       pound  \n",
       "3        pack  \n",
       "4     healthy  \n",
       "5        soda  \n",
       "6      reason  \n",
       "7  complexion  \n",
       "8     drinker  \n",
       "9        kick  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_cols = ['Topic 0', 'Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5', 'Topic 6']\n",
    "topics_df = pd.DataFrame(columns=topic_cols)\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        \n",
    "        top_words = []\n",
    "        for i in topic.argsort()[:-no_top_words - 1:-1]:\n",
    "            top_words.append(feature_names[i])\n",
    "                             \n",
    "        topics_df[\"Topic {}\".format(topic_idx)] = top_words\n",
    "    return topics_df\n",
    "        \n",
    "    \n",
    "        \n",
    "# Run NMF\n",
    "no_topics = 7\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(X)\n",
    "\n",
    "no_top_words = 20\n",
    "display_topics(nmf, feature_names, no_top_words).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
